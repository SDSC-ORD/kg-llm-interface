{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question to SPARQL query generation\n",
    "\n",
    "In this notebook, we generate a SPARQL query from an input plain english question and execute it against a knowledge graph.\n",
    "\n",
    "Below are the two prompts we will use for the language model. First, the `SPARQL_TEMPLATE` is used to construct a SPARQL query from an input quersion and context. Then, the output will be executed against the knowledge graph and the `ANSWER_TEMPLATE` will be used to generate a human-readable answer to described the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SPARQL_TEMPLATE = \"\"\"\n",
    "Generate a SPARQL query to answer the input question. A sample of the knowledge graph schema is provided to help construct the query.\n",
    "After you generate the sparql, you should display it.\n",
    "When generating sparql:\n",
    "* never enclose the sparql in back-quotes.\n",
    "* always include the prefix declarations.\n",
    "* prefer using OPTIONAL when selecting multiple variables.\n",
    "* Allow case-insensitive matching of strings.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question for which you must generate a SPARQL query\n",
    "Information: the schema information in RDF format. This will help you generate the sparql query with the correct format.\n",
    "\n",
    "Question: {question_str}\n",
    "Information:\n",
    "{context_str}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "ANSWER_TEMPLATE = \"\"\"\n",
    "The following describe a user question, associated SPARQL query and the result from executing the query.\n",
    "Based on this information, write an answer in simple terms that describes the results.\n",
    "When appropriate, use markdown formatting to format the results into a table or bullet points.\n",
    "\n",
    "Question:\n",
    "{question_str}\n",
    "Query:\n",
    "{query_str}\n",
    "Result:\n",
    "{result_str}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup a minimal configuration, with the vector database (Chroma) running in client-only mode, and a small RDF file acting as the knowledge graph. This file contains both the instance data and the ontology. The ontology is enclosed in a named graph inside the file.\n",
    "\n",
    "For the sake of the demo, we use a small model for embeddings (MiniLM-L6-V2) and rely on the OpenAI key for text geneartion for text generation. A local model can be used instead, but it will require high RAM and ideally a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aikg.config import ChatConfig, ChromaConfig, SparqlConfig\n",
    "\n",
    "chroma_config = ChromaConfig(\n",
    "    host=\"local\",\n",
    "    port=8000,\n",
    "    collection_name=\"test\",\n",
    "    embedding_model=\"all-MiniLM-L6-v2\",\n",
    "    persist_directory=\"/tmp/chroma-test/\",\n",
    ")\n",
    "sparql_config = SparqlConfig(\n",
    "    endpoint=\"../data/test_data.trig\",\n",
    ")\n",
    "chat_config = ChatConfig(\n",
    "    model_id=\"lmsys/vicuna-7b-v1.3\",\n",
    "    max_new_tokens=48,\n",
    "    max_input_size=2048,\n",
    "    num_output=256,\n",
    "    max_chunk_overlap=20,\n",
    "    answer_template=ANSWER_TEMPLATE,\n",
    "    sparql_template=SPARQL_TEMPLATE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from aikg.utils.llm import setup_llm_chain\n",
    "from aikg.utils.rdf import setup_kg\n",
    "\n",
    "\n",
    "# Use a local model\n",
    "from aikg.utils.llm import setup_llm\n",
    "#llm = setup_llm(chat_config.model_id, chat_config.max_new_tokens)\n",
    "# Use OpenAI API\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "# For now, both chains share the same model to spare memory\n",
    "answer_chain = setup_llm_chain(llm, chat_config.answer_template)\n",
    "sparql_chain = setup_llm_chain(llm, chat_config.sparql_template)\n",
    "kg = setup_kg(**sparql_config.dict())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to embed the ontology into the vector database. This will allow us to retrieve semantically similar concepts from the ontology based on the question.\n",
    "\n",
    "In the example rdf file, the ontology is enclosed in a named graph calles `http://example.org/ontology`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:01.497 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'chroma-build-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:01.497 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'grinning-perch'\u001b[0m for flow\u001b[1;35m 'chroma-build-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:01.848 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span> Started\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:01.848 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - \u001b[36mINFO\u001b[0m Started\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:01.929 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Created task run 'init_chromadb-0' for task 'init_chromadb'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:01.929 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Created task run 'init_chromadb-0' for task 'init_chromadb'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:01.932 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Executing 'init_chromadb-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:01.932 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Executing 'init_chromadb-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmatthey/.cache/pypoetry/virtualenvs/aikg-ULDgE_fB-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)e9125/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 4.23MB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 470kB/s]\n",
      "Downloading (…)7e55de9125/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 25.6MB/s]\n",
      "Downloading (…)55de9125/config.json: 100%|██████████| 612/612 [00:00<00:00, 2.09MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 434kB/s]\n",
      "Downloading (…)125/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 49.5MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:19<00:00, 4.73MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 179kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 277kB/s]\n",
      "Downloading (…)e9125/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.59MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 1.06MB/s]\n",
      "Downloading (…)9125/train_script.py: 100%|██████████| 13.2k/13.2k [00:00<00:00, 35.2MB/s]\n",
      "Downloading (…)7e55de9125/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 6.12MB/s]\n",
      "Downloading (…)5de9125/modules.json: 100%|██████████| 349/349 [00:00<00:00, 1.20MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:33.417 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'init_chromadb-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:33.417 | \u001b[36mINFO\u001b[0m    | Task run 'init_chromadb-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:33.503 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Created task run 'sparql_to_documents-0' for task 'sparql_to_documents'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:33.503 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Created task run 'sparql_to_documents-0' for task 'sparql_to_documents'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:33.507 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Executing 'sparql_to_documents-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:33.507 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Executing 'sparql_to_documents-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:34.041 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'sparql_to_documents-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:34.041 | \u001b[36mINFO\u001b[0m    | Task run 'sparql_to_documents-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:34.046 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Indexing by batches of 50 items\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:34.046 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Indexing by batches of 50 items\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:34.110 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Created task run 'index_batch-0' for task 'index_batch'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:34.110 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Created task run 'index_batch-0' for task 'index_batch'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:34.115 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Executing 'index_batch-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:34.115 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Executing 'index_batch-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:34.522 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'index_batch-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:34.522 | \u001b[36mINFO\u001b[0m    | Task run 'index_batch-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:34.526 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Indexed 9 items.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:34.526 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Indexed 9 items.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">15:04:34.664 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'grinning-perch'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "15:04:34.664 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'grinning-perch'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `tuple`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `list`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`'))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aikg.flows.chroma_build import chroma_build_flow\n",
    "chroma_build_flow(chroma_config, sparql_config, graph=\"https://example.org/ontology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from aikg.utils.chroma import setup_client, setup_collection\n",
    "client = setup_client(\n",
    "    chroma_config.host,\n",
    "    chroma_config.port,\n",
    "    chroma_config.persist_directory,\n",
    ")\n",
    "collection = setup_collection(\n",
    "    client,\n",
    "    chroma_config.collection_name,\n",
    "    chroma_config.embedding_model,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chroma collection now contains the ontology concepts as vectors. We can retrieve the most similar concepts to a given question.\n",
    "Notice that the property \"programmingLanguage\" is retrieved, even though the question does not contain the word \"programming\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://schema.org/programmingLanguage> <http://www.w3.org/2000/01/rdf-schema#comment> \"The computer programming language.\" .\n",
      "<http://schema.org/programmingLanguage> <http://www.w3.org/2000/01/rdf-schema#label> \"programming language\" .\n",
      "<http://schema.org/programmingLanguage> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .\n",
      "<http://schema.org/programmingLanguage> <http://www.w3.org/2000/01/rdf-schema#domain> <http://schema.org/SoftwareSourceCode> .\n",
      "<http://schema.org/programmingLanguage> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Property> .\n",
      "\n",
      "<http://schema.org/codeRepository> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#anyUri> .\n",
      "<http://schema.org/codeRepository> <http://www.w3.org/2000/01/rdf-schema#comment> \"Link to the repository where the un-compiled, human readable code and related code is located (SVN, GitHub, CodePlex).\" .\n",
      "<http://schema.org/codeRepository> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Property> .\n",
      "<http://schema.org/codeRepository> <http://www.w3.org/2000/01/rdf-schema#label> \"codeRepository\" .\n",
      "<http://schema.org/codeRepository> <http://www.w3.org/2000/01/rdf-schema#domain> <http://schema.org/SoftwareSourceCode> .\n",
      "\n",
      "<http://schema.org/license> <http://www.w3.org/2000/01/rdf-schema#comment> \"A license document that applies to this content, typically indicated by URL.\" .\n",
      "<http://schema.org/license> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .\n",
      "<http://schema.org/license> <http://www.w3.org/2000/01/rdf-schema#label> \"license\" .\n",
      "<http://schema.org/license> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Property> .\n",
      "<http://schema.org/license> <http://www.w3.org/2000/01/rdf-schema#domain> <http://schema.org/SoftwareSourceCode> .\n",
      "<http://schema.org/license> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#anyUri> .\n",
      "\n",
      "<http://schema.org/name> <http://www.w3.org/2000/01/rdf-schema#comment> \"The name of the item.\" .\n",
      "<http://schema.org/name> <http://www.w3.org/2000/01/rdf-schema#domain> <http://schema.org/SoftwareSourceCode> .\n",
      "<http://schema.org/name> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .\n",
      "<http://schema.org/name> <http://www.w3.org/2000/01/rdf-schema#label> \"name\" .\n",
      "<http://schema.org/name> <http://www.w3.org/2000/01/rdf-schema#domain> <http://schema.org/Organization> .\n",
      "<http://schema.org/name> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Property> .\n",
      "<http://schema.org/name> <http://www.w3.org/2000/01/rdf-schema#domain> <http://schema.org/Person> .\n",
      "\n",
      "<http://schema.org/keywords> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .\n",
      "<http://schema.org/keywords> <http://www.w3.org/2000/01/rdf-schema#domain> <http://schema.org/SoftwareSourceCode> .\n",
      "<http://schema.org/keywords> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Property> .\n",
      "<http://schema.org/keywords> <http://www.w3.org/2000/01/rdf-schema#label> \"keywords\" .\n",
      "<http://schema.org/keywords> <http://www.w3.org/2000/01/rdf-schema#comment> \"Keywords or tags used to describe some item. Multiple textual entries in a keywords list are typically delimited by commas, or by repeating the property.\" .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"What softwares are written in Python?\"\n",
    "results = collection.query(query_texts=QUESTION, n_results=5)\n",
    "print('\\n'.join([res.get(\"triples\", \"\") for res in results['metadatas'][0]]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can generate the SPARQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PREFIX schema: <http://schema.org/>\n",
      "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
      "\n",
      "SELECT ?name \n",
      "WHERE { \n",
      "  ?software schema:programmingLanguage ?language .\n",
      "  ?software schema:name ?name .\n",
      "  FILTER (?language = \"Python\"^^xsd:string)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from aikg.utils.chat import generate_sparql\n",
    "query = generate_sparql(QUESTION, collection, sparql_chain)\n",
    "print(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and execute it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(rdflib.term.Literal('SDSC-ORD/gimie'),), (rdflib.term.Literal('SDSC-ORD/zarr_linked_data'),)]\n"
     ]
    }
   ],
   "source": [
    "from aikg.utils.rdf import query_kg\n",
    "results = query_kg(kg, query)\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate a human-readable answer from the results of the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The query returned two softwares written in Python: SDSC-ORD/gimie and SDSC-ORD/zarr_linked_data.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aikg.utils.chat import generate_answer\n",
    "generate_answer(QUESTION, query, results, answer_chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aikg-URVQdnEY-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
